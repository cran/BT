<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Gireg Willame" />

<meta name="date" content="2023-01-28" />

<title>Getting started with the BT package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Getting started with the BT package</h1>
<h4 class="author">Gireg Willame</h4>
<h4 class="date">2023-01-28</h4>



<div id="bt" class="section level1">
<h1>BT</h1>
<p>The <code>BT</code> package implements (Adaptive) Boosting Tree for
<em>Poisson</em> distributed response variables, using log-link
function. When presented with data, the <code>BT</code> package offers
the user the ability to build predictive models and explore the
influence of different variables on the response, akin to a data mining
or exploration task. The built package is based on the original idea
proposed by D. Hainaut, J. Trufin and M. Denuit. For more theoretical
details, we refer to the following references:</p>
<ul>
<li>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective
Statistical Learning Methods for Actuaries |: GLMs and
Extensions</strong>, <em>Springer Actuarial</em>.</li>
<li>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective
Statistical Learning Methods for Actuaries ||: Tree-Based Methods and
Extensions</strong>, <em>Springer Actuarial</em>.</li>
<li>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective
Statistical Learning Methods for Actuaries |||: Neural Networks and
Extensions</strong>, <em>Springer Actuarial</em>.</li>
<li>M. Denuit, D. Hainaut and J. Trufin (2022). <strong>Response versus
gradient boosting trees, GLMs and neural networks under Tweedie loss and
log-link</strong>, Accepted for publication in <em>Scandinavian
Actuarial Journal</em>.</li>
<li>M. Denuit, J. Huyghe and J. Trufin (2022). <strong>Boosting
cost-complexity pruned trees on Tweedie responses: The ABT machine for
insurance ratemaking</strong>. Paper submitted for publication.</li>
<li>M. Denuit, J. Trufin and T. Verdebout (2022). <strong>Boosting on
the responses with Tweedie loss functions</strong>. Paper submitted for
publication.</li>
</ul>
<p>To get started with the package a user must:</p>
<ul>
<li>have a dataset in a <code>data.frame</code>.</li>
<li>set the appropriate parameters for the <code>BT</code> model.</li>
</ul>
<p>Once these steps have been completed, a user can fit their
<code>BT</code> model by a call to <code>BT</code> and subsequently:
evaluate its performance, make predictions, fit additional trees and
plot the relative influence of the various predictor variables</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(BT)</span></code></pre></div>
<div id="define-a-database" class="section level2">
<h2>Define a database</h2>
<p>To demonstrate the <code>BT</code> usage, we’ll use a simulated
database where the response variable is Poisson distributed. The built
database contains <span class="math inline">\(n = 50000\)</span> records
as well as the following simulated variables (with their interpretation
in an insurance MTPL context):</p>
<ul>
<li><code>Y</code>, the Poisson distributed response variable (e.g. the
number of claims).</li>
<li><code>Gender</code>, <code>Age</code> and <code>Sport</code> which
are directly linked to the response variable (e.g. resp. the
policyholder’s gender and age, the vehicle type).</li>
<li><code>Split</code> which is not linked to the response
variable.</li>
<li><code>ExpoR</code> which corresponds to the time-exposure (e.g. the
well-known exposure-to-risk).</li>
<li>Based on these variables, we define the rate as
<code>Y_normalize = Y/ExpoR</code>.</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50000</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>Gender <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;male&quot;</span>,<span class="st">&quot;female&quot;</span>),n,<span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>Age <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">18</span><span class="sc">:</span><span class="dv">65</span>),n,<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>Split <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>),n,<span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>Sport <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;yes&quot;</span>,<span class="st">&quot;no&quot;</span>),n,<span class="at">replace=</span><span class="cn">TRUE</span>))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">0.1</span><span class="sc">*</span><span class="fu">ifelse</span>(Gender<span class="sc">==</span><span class="st">&quot;male&quot;</span>,<span class="fl">1.1</span>,<span class="dv">1</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> lambda<span class="sc">*</span>(<span class="dv">1</span><span class="sc">+</span><span class="dv">1</span><span class="sc">/</span>(Age<span class="dv">-17</span>)<span class="sc">^</span><span class="fl">0.5</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> lambda<span class="sc">*</span><span class="fu">ifelse</span>(Sport<span class="sc">==</span><span class="st">&quot;yes&quot;</span>,<span class="fl">1.15</span>,<span class="dv">1</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>ExpoR <span class="ot">&lt;-</span> <span class="fu">runif</span>(n)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, ExpoR<span class="sc">*</span>lambda)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>Y_normalized <span class="ot">&lt;-</span> Y<span class="sc">/</span>ExpoR</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Y,Gender,Age,Split,Sport,ExpoR, Y_normalized)</span></code></pre></div>
</div>
<div id="define-the-bt-parameters" class="section level2">
<h2>Define the <code>BT</code> parameters</h2>
<p>Once the database has been imported, the user needs to define the
different parameters that will be passed to the algorithm. In this case,
the parameters should not be stored upfront in a specific object and a
simple call using the argument can be made. We list below all the
available parameters:</p>
<ul>
<li><code>formula</code>: a symbolic description of the model to be fit.
We emphasize that the offset are not supported with out approach.</li>
<li><code>data</code>: the database on which the computations will be
performed.</li>
<li><code>tweedie.power</code>: Experimental parameter : the Tweedie
power referencing to the response variable distribution. Always set to 1
referring to Poisson distribution.</li>
<li><code>ABT</code>: bool value to define whether we fit a Boosting
Tree (=<code>FALSE</code>) or an Adaptive Boosting Tree
(=<code>TRUE</code>).</li>
<li><code>n.iter</code>: the number of iterations to user in the
fitting.</li>
<li><code>train.fraction</code>: the percentage of the <code>data</code>
that will be used as training set. The remaining part will be used as
validation set.</li>
<li><code>interaction.depth</code>: the maximum number of splits in a
tree present in the expansion.</li>
<li><code>shrinkage</code>: acts as regularization for additional
iterations - the smaller the shrinkage generally the better the
performance of the fit. However, smaller shrinkage implies that the
number of trees may need to be increased to achieve a certain
performance.</li>
<li><code>bag.fraction</code>: the fraction of the training observations
randomly sub-sampled to fit a tree in each iteration. This has the
effect of reducing the variance of the boosted model.</li>
<li><code>colsample.bytree</code>: the number of variables randomly
sampled that will be used to build the next tree in the expansion.</li>
<li><code>keep.data</code>: allows the user the save the different
databases used during the algorithm in a <code>BTData</code>
object.</li>
<li><code>is.verbose</code>: whether the algorithm evolution has to be
printed out.</li>
<li><code>cv.folds</code>: the number of cross-validation folds to
create. If set to 1 (by default), no cross-validation is performed.</li>
<li><code>folds.id</code>: used in case of cross-validation. If defined,
allows the user to specify in what fold each observation belongs. If
<code>cv.folds</code> is greater than 1 and <code>folds.id</code> is
well defined, the latter will take over.</li>
<li><code>n.cores</code>: in case of cross-validation, the number of
cores used to perform the parallelization. Please note that in the
cross-validation context, a call to the <code>parLapply</code> function
is made (whatever the number of cores). This parameter is originally set
to <code>cv.folds</code>.</li>
<li><code>tree.control</code>: the proposed algorithm is based on the
<code>rpart</code> package. This parameter will be used to originally
build each tree in the expansion. We emphasize that if the
<code>interaction.depth</code> is set to <code>NULL</code>, each tree in
the expansion will be built thanks to this parameters with no further
treatment. We recommend this option for advanced user only.</li>
<li><code>weights</code>: a vector representing the weight given to each
observation. By default, each observation as the same weight (=1).</li>
<li><code>seed</code>: some of the parameters bring randomness during
the algorithm. This parameter allows the user to replicate the
results.</li>
</ul>
<p>We emphasize that performing a cross-validation will produce a first
global model trained on the full training set as well as different cv
related <code>BT</code> models. The former will generally further be
used while the later will help to e.g. determine the performances.</p>
</div>
<div id="application-to-the-created-database" class="section level2">
<h2>Application to the created database</h2>
<p>Let us now build the first model. Let us note/suppose that:</p>
<ul>
<li>As already mentioned, the simulated response variable <code>Y</code>
follows a Poisson distribution. This first step can normally be achieved
thanks to a short database analysis.</li>
<li>The user wants to use all available explanatory variables to explain
the response variable <code>Y</code>. In usual MTPL pricing, the
<code>ExpoR</code> variable allows to consider the time-exposure to risk
(e.g. the Policyholder contract’s duration). The latter variable is thus
generally set in offset. In a Tweedie framework with log-link function,
we emphasize that working with offset is equivalent to build a model on
the rate response variable and adjusted weights. More precisely, the
variable <code>Y_normalized</code> will be used as response variables
with weights given by <code>ExpoR</code> (instead of original values,
i.e. 1). This choice was made during modelling by the author.</li>
<li>We’ll work in the context of Boosting Tree and perform 300
iterations (=<code>n.iter</code>).</li>
<li>The <code>interaction.depth</code> and <code>shrinkage</code>
parameters will respectively be set to 4 and 0.01.</li>
<li>The <code>train.fraction</code> will be set to 0.8, meaning that the
first <code>0.8*nrow(data)</code> will be considered as training set and
the remaining <code>data</code> records as validation set. Moreover,
random effects such as bagging and columns sample for each tree will be
defined. The <code>bag.fraction</code> and <code>colsample.bytree</code>
parameters will respectively be set to 0.5 and 3.</li>
<li>3-cv will be performed for this example.</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>BT_algo <span class="ot">&lt;-</span> <span class="fu">BT</span>(<span class="at">formula =</span> <span class="fu">as.formula</span>(<span class="st">&quot;Y_normalized ~ Age + Sport + Split + Gender&quot;</span>),</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> dataset,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">ABT =</span> F,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">n.iter =</span> <span class="dv">300</span>,</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">train.fraction =</span> <span class="fl">0.8</span>,</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">interaction.depth =</span> <span class="dv">4</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">shrinkage =</span> <span class="fl">0.01</span>,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">bag.fraction =</span> <span class="fl">0.5</span>,</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">colsample.bytree =</span> <span class="dv">3</span>,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">keep.data =</span> T,</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">is.verbose =</span> F,</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">cv.folds =</span> <span class="dv">3</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">folds.id =</span> <span class="cn">NULL</span>,</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">n.cores =</span> <span class="dv">1</span>,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>              <span class="at">weights =</span> ExpoR,</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">seed =</span> <span class="dv">44</span>)</span></code></pre></div>
<p>Now that the first fit is made, we’ll focus on the different
results/functions that are available within the package.</p>
<div id="bt-outputs" class="section level3">
<h3><code>BT</code> outputs</h3>
<p>Multiple results are stored in the <code>BT_algo</code> run (namely,
a <code>BTFit</code> object)</p>
<p>First of all, almost all the parameters that have been used during
the call are stored in the result object:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;Fitting parameters</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>call</span></code></pre></div>
<pre><code>## BT(formula = as.formula(&quot;Y_normalized ~ Age + Sport + Split + Gender&quot;), 
##     data = dataset, ABT = F, n.iter = 300, train.fraction = 0.8, 
##     interaction.depth = 4, shrinkage = 0.01, bag.fraction = 0.5, 
##     colsample.bytree = 3, keep.data = T, is.verbose = F, cv.folds = 3, 
##     folds.id = NULL, n.cores = 1, weights = ExpoR, seed = 44)</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>distribution</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>BTParams</span></code></pre></div>
<pre><code>## $ABT
## [1] FALSE
## 
## $train.fraction
## [1] 0.8
## 
## $shrinkage
## [1] 0.01
## 
## $interaction.depth
## [1] 4
## 
## $bag.fraction
## [1] 0.5
## 
## $n.iter
## [1] 300
## 
## $colsample.bytree
## [1] 3
## 
## $tree.control
## $tree.control$minsplit
## [1] 2
## 
## $tree.control$minbucket
## [1] 1
## 
## $tree.control$cp
## [1] -Inf
## 
## $tree.control$maxcompete
## [1] 4
## 
## $tree.control$maxsurrogate
## [1] 5
## 
## $tree.control$usesurrogate
## [1] 2
## 
## $tree.control$surrogatestyle
## [1] 0
## 
## $tree.control$maxdepth
## [1] 4
## 
## $tree.control$xval
## [1] 0
## 
## 
## attr(,&quot;class&quot;)
## [1] &quot;BTParams&quot;</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>keep.data</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>is.verbose</span></code></pre></div>
<pre><code>## [1] FALSE</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>seed</span></code></pre></div>
<pre><code>## [1] 44</code></pre>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>cv.folds <span class="co"># #used folds</span></span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>folds, <span class="dv">10</span>) <span class="co"># folds created.</span></span></code></pre></div>
<pre><code>##  [1] 2 2 1 1 3 3 3 1 3 1</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Name of weights, response and explnatory variables used</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>w</span></code></pre></div>
<pre><code>## [1] &quot;w&quot;</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>response</span></code></pre></div>
<pre><code>## [1] &quot;Y_normalized&quot;</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>var.name</span></code></pre></div>
<pre><code>## [1] &quot;Age&quot;    &quot;Sport&quot;  &quot;Split&quot;  &quot;Gender&quot;</code></pre>
<p>One can then continue by having a look at the initialization that is
performed as well as the related errors:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tweedie with intercept only.</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>BTInit<span class="sc">$</span>initFit </span></code></pre></div>
<pre><code>## [1] 0.1480054</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Init training error</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>BTInit<span class="sc">$</span>training.error</span></code></pre></div>
<pre><code>## [1] 0.3685759</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Init validation error</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>BTInit<span class="sc">$</span>validation.error</span></code></pre></div>
<pre><code>## [1] 0.3528488</code></pre>
<p>If <code>keep.data = TRUE</code>, the created training and validation
set are also returned:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTData<span class="sc">$</span>training.set)</span></code></pre></div>
<pre><code>##   Y_normalized Age Sport Split Gender          w currTrainScore
## 1            0  28   yes    no female 0.10197573      -1.878222
## 2            0  62    no   yes   male 0.71179081      -2.021452
## 3            0  37    no    no   male 0.37298030      -1.915680
## 4            0  56   yes    no   male 0.62134765      -1.895872
## 5            0  36   yes    no   male 0.10604182      -1.846164
## 6            0  24   yes   yes female 0.05905927      -1.866964</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTData<span class="sc">$</span>validation.set, <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##       Y_normalized Age Sport Split Gender         w currValScore
## 40001      0.00000  49   yes    no female 0.9998001    -1.876190
## 40002      0.00000  39    no   yes   male 0.7711231    -1.991724
## 40003      0.00000  29   yes   yes   male 0.1610786    -1.834477
## 40004      0.00000  33    no   yes female 0.5680789    -2.038986
## 40005      2.98261  40   yes    no female 0.3352768    -1.895784</code></pre>
<p>One can also have a look at the fitted values (on the score scale) as
well as the errors computed across the different iterations (on training
set, validation set, the OOB improvement and the cross-validation
error):</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtained fitting results at the end - Full BT and CV. </span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>fitted.values)</span></code></pre></div>
<pre><code>## [1] -1.878222 -2.021452 -1.915680 -1.895872 -1.846164 -1.866964</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>cv.fitted) <span class="co"># cv fitted.</span></span></code></pre></div>
<pre><code>## [1] -1.892785 -1.934626 -1.995363 -1.854360 -1.845289 -1.889145</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Errors computed.</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTErrors<span class="sc">$</span>training.error)</span></code></pre></div>
<pre><code>## [1] 0.3637171 0.3691590 0.3623403 0.3644938 0.3650795 0.3699250</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTErrors<span class="sc">$</span>validation.error)</span></code></pre></div>
<pre><code>## [1] 0.3528371 0.3528110 0.3528009 0.3527770 0.3527524 0.3527456</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTErrors<span class="sc">$</span>oob.improvement)</span></code></pre></div>
<pre><code>## [1] 2.336664e-05 3.498181e-05 9.592938e-06 2.194806e-05 2.780747e-05
## [6] 1.158397e-05</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTErrors<span class="sc">$</span>cv.error)</span></code></pre></div>
<pre><code>## [1] 0.3685543 0.3685281 0.3685146 0.3684967 0.3684822 0.3684594</code></pre>
<p>Finally, we note that all the trees fitted during the algorithm are
stored in the <code>BTIndivFits</code> list:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>BT_algo<span class="sc">$</span>BTIndivFits[[<span class="dv">1</span>]] <span class="co"># First tree in the expansion</span></span></code></pre></div>
<pre><code>## n= 20000 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
##  1) root 20000 7274.6970 0.9851696  
##    2) Age&gt;=18.5 19600 7038.6580 0.9661252  
##      4) Age&gt;=38.5 11193 3896.8360 0.9131932 *
##      5) Age&lt; 38.5 8407 3136.2120 1.0370160  
##       10) Gender=female 4225 1474.3530 0.9393184  
##         20) Age&gt;=19.5 4026 1380.0720 0.9104576 *
##         21) Age&lt; 19.5 199   89.4214 1.5041700 *
##       11) Gender=male 4182 1656.0760 1.1354260 *
##    3) Age&lt; 18.5 400  215.7846 1.8509420 *</code></pre>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One can also access to the usual tree outputs.</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(BT_algo<span class="sc">$</span>BTIndivFits[[<span class="dv">1</span>]]<span class="sc">$</span>frame)</span></code></pre></div>
<pre><code>##       var     n        wt      dev      yval   complexity ncompete nsurrogate
## 1     Age 20000 1478.9331 7274.697 0.9851696 0.0027842524        2          0
## 2     Age 19600 1448.0725 7038.658 0.9661252 0.0007830279        2          0
## 4  &lt;leaf&gt; 11193  829.0393 3896.836 0.9131932 0.0007353703        0          0
## 5  Gender  8407  619.0332 3136.212 1.0370160 0.0007830279        2          2
## 10    Age  4225  310.9132 1474.353 0.9393184 0.0006680935        1          0
## 20 &lt;leaf&gt;  4026  296.6375 1380.072 0.9104576         -Inf        0          0
##         yval2.1      yval2.2
## 1     0.9851696 1457.0000000
## 2     0.9661252 1399.0000000
## 4     0.9131932  757.0000000
## 5     1.0370160  642.0000000
## 10    0.9393184  292.0000000
## 20    0.9104576  270.0000000</code></pre>
</div>
<div id="bt_perf-function" class="section level3">
<h3><code>BT_perf</code> function</h3>
<p>This function allows the user to determine the best number of
iterations that has to be performed. This one also depends on the type
of errors that are available/have been computed during training
phase.</p>
<ul>
<li>The <code>training.error</code> is automatically computed. Please
note that in case of bagging used, this corresponds to the in-bag errors
(i.e. a random sub-selection of the original training set).</li>
<li>If a <code>train.fraction</code> has properly be defined, a
<code>validation.error</code> will be computed on the validation
set.</li>
<li>If a <code>bag.fraction</code> has properly be defined, an
<code>oob.improvement</code> vector will be computed.</li>
<li>If cross-validation parameters have been filled, a
<code>cv.error</code> will be computed.</li>
</ul>
<p>These values are stored in the <code>BTErrors</code> object as
previously shown.</p>
<p>Depending on the chosen approach, the following methods can be
applied to compute the best number of iterations.</p>
<ul>
<li>If user wants to use the <code>validation.error</code>, the
<code>argmin(BT$BTErrors$validation.error)</code> will be returned as
optimal iteration.</li>
<li>If user wants to use the <code>oob.improvement</code>, the
<code>argmin(-cumsum(BT$BTErrors$oob.improvement))</code> will be
returned as optimal iteration. To be precise, the
<code>oob.improvement</code> are not used as such but a smoothed version
of it.</li>
<li>If user wants to use the <code>cv.error</code>, the
<code>argmin(BT$BTErrors$cv.error)</code> will be returned as optimal
iteration.</li>
</ul>
<p>We now present the function arguments:</p>
<ul>
<li><code>BTFit_object</code>: a <code>BT</code> algorithm result. In
our case, <code>BT_algo</code>.</li>
<li><code>method</code>: Allows the user to specify the method that has
to be applied to compute the best number of iterations. This can be set
to <code>validation</code>, <code>OOB</code> or <code>cv</code>
depending whether the user wants to use <code>validation.error</code>,
<code>oob.improvement</code> or <code>cv.error</code> as previously
explained. We emphasize that without specifying the <code>method</code>
argument a best guest approach will be performed.</li>
<li><code>plot.it</code>, <code>oobag.curve</code>, <code>overlay</code>
and <code>main</code>: plot related parameters. If desired, the
<code>BT_perf</code> function plots the computed errors alongside
returning the optimal iteration.</li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>optimal_perf_validation <span class="ot">&lt;-</span> <span class="fu">BT_perf</span>(BT_algo, <span class="at">method=</span><span class="st">&#39;validation&#39;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>optimal_perf_oob <span class="ot">&lt;-</span> <span class="fu">BT_perf</span>(BT_algo, <span class="at">method=</span><span class="st">&#39;OOB&#39;</span>, <span class="at">oobag.curve =</span> <span class="cn">TRUE</span>, <span class="at">overlay =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## OOB generally underestimates the optimal number of iterations although predictive performance is reasonably competitive.
##             Using cv_folds&gt;1 when calling BT usually results in improved predictive performance.</code></pre>
<p><img src="data:image/png;base64,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" /><!-- --><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAXVBMVEUAAAAAADoAAGYAAP8AOpAAZrY6AAA6ADo6AGY6kNtmAABmADpmAGZmtrZmtv+QOgCQkGaQtpCQ2/+2ZgC225C2///bkDrb/7bb////AAD/tmb/25D//7b//9v///8Zzr9yAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAML0lEQVR4nO2dDXvbKAzH2br21uxuvVuuuSVN+f4f88yLAPkFyTaJCdb/eba1sUPIbyCEBFhpr+tBOX1916IotXUFapcAIpQA6jrZt9/H1+3qUqUioMuXX6dvv68HIYQUAH2+veoOkD6JkUYKgK6HnxbQRQAhDVrQsfsjiurboJP6uWFtKhQexZT68mu7ulQp8YMICSBCySimnresSK2KLcjPVsUIYfW72PUgfhASAmQakbQgrAjo40ViQSNKjLTQGVPSxbomJOPYQNhIn5TMNHqSUYxQBHSUoP2YUk9aRvgRyVyMEB7FxE8cKAmYKROul4BZTyjkanSSkCsSCtobSdAeS1oQIbFBhGQUIyR+ECEBRKifFxMT3RPKrHZ/n8QIYSXDvBu+JDePFR3FH67piKOINWhB4ihipY6iISSOYk9pwCxIelmU+EGEBBAhB+j6Z9qp8G87l29BcfHL55uYoFTpKOYkoxiS2CBCAoiQACIkgAgJIEICiJDsFyMk+8UIyX4xQrJfjJDsFyMk+8UIyX4xQuIHERJAhBJAxjy7NTCiqGSdtB2+rgfZjoAkS/AIDZfgCSCk2MWcB/TxIkYISZbgEZJhnpAAIhQBfb7JyoURJX6QkBlT4gfJ8DWmgaMowkocRZljjKm/BE/U03AJnthqJPGDCAkgQoPzg6SLYaGA2em5m7GuMtVqhZ7WvDnRaib4G8EPxlG8mMzqqrzYmto9rXhvoSrkijOO4sf3d/unQHELVDkgE1E0G1oE0FRxJtZ6fC3RxRZWsXZA+vhsRrJ1g1jTgIoVJ4CI4gQQUVyDgDonqMxkNQU0t6Y1AypbnAAiimsTUJlVCw0Dsqfgrc6rtgxI+y1jqxpS44C0mZItGcVwrKFdQNKCMsXZzHPeBrnc4iXnKzUMiDGKWUB2tj+ZZWwYEEMGkEczFRTxgKwtag4QuR3KAPIx66mVjC0DordD7bsFMbZDufnss84sBWkYEG87lDtUeXq5ecOAymyHahhQme1QDpBqEhBnOxS5jrFpQLROYHsmjVAEpHYICHYraGqYt4BmJ8lrBsQ7wCyZYOQdxfYAGbluc8kYoYUtiFvjygHBIs5c6jkMcXkbdD63CIi1Xwy64iRED+icLtRpBBD0nwKOYpuA4CROOm6fmKKJ4jyhwUfkVTsg9nnSNCDlCA0/IqvqAXE1Aqi3QNAAOgug6eKUa0LwG7PcXQFSCBDvQ5oBRBenXBPaJ6B85DoAUtEK7QsQEbkGQNp3MvcaD1H1gDiHvFGR61FAqg1ArEPeqMg1AnRuChDvkDcqcp0AUmCmuRsoKgfEPOSNiFwPAakUULbylQPiZjXykesISCs33WgGUMGshgcEzmIrgIoc8jYCCOZlMNpPfoHqATF0Uv5Id3qY7wFSuwBkgkVuHREf0HlHgNws9fON5Sj6cezs/zw4IN5WBAhbm92tfEC2Ffko/sMC4inEOY7PLEDQvXYDKHSs6X13GJAKgM4w2mdmHTUD4j4aCrykydXUQ0DWB/JpjscFZERnVjOl9GLSAAgSiGOABl+kckCczCq3uASQ8oDOCaCJUHXlgMqcxBmmFM51Vn6tkMKAFPpkUOWACmZWMSCtfB7Ih6mhIz4aIH5mlVHcABAQinNXNz1LVTugIk/qTWftfUCOEgaUfpvqARUsDgBpsDdOZ5iYCaD4VwooInpIQCUeXaP6P0dA3it6XEBFHl0zCUgHt9GnOwKg0NqeBmZ7dRUKCA3z6x9dM6gdnt5r38+c9dZgwx8CUJlH1zAAaZ+3V9Dz4LbKARXcqzF8AQb7aIdUH5A5w0yXOIDsxjaoSFZj8IICawMTD2eovXft5x8B0LqveGNHsUhWY/gyBuQIndP5RwTEy1PPrkLdxanYlBwlYKNg/jECaGHVHhWQ/yFwgvl9nMM+JUMbvGlB9R7HUcxcV4mgm1UPqLijmLmexBdj5uzJT9IgvA8miyhqbhVm6taO4vh1BAga0QCQj9fiptT/4W6AGI4i92gK+uNQhBq62VPI4Vu7PQSEfYCtWlDGUZw+miIYlKcKdCNADEeRe7AA/XExjeh/M78/nVMlfjY0JaVQCVqH8G36wRs6ityjKTgfl5pfAKRDXDZGHoNjmQICbwmSJuCJsqowU3OKK9CC4o3oTg8obGHwszWPK/wLOSNwBuoDZOpDH00x/4MDIAhY6/NAwa57HDGVBLTmf6M59ey+PePsKdbRFPM+2P9iAUFE3xMCJ+kMgUgY/5VPJGFvYW4VZtbT5+eLpH0WvC0ACp1IwcRNgzsZAaFmdSdATtfDTR3F6bc5QMk0owcoTEm80dYK1kao0PKwo1RGqDjTiLItiHc0xbJa5AA5BN5Ua9goA7Y89sQVVchVzck8wY9oPcyjKZbVYghIp4CAkKMB7KKB8s7TLY002be4BwssrEkfkMaAtNLI9OjUGPmwwMoqjFYr/tg1ofw4xj2aYmFN7BwBAYIxPQAKi4qTfGQYzO5gg8w66ExI+uYtCJWAALkXwDVEgGK65A6AiJ7GPJpiYU16s0wGID8ZCxO12wI6KmKE0tyjKRZqClB8IQznEdr9ADkfuVhxC0QBCoiSiRy4QTqYrS3nYl70tvBlmgCEXlKxpbhX7gRo1hMgtwSkxwDhe3cDaKQ4AUQUJ4AYxWFAI3mPGwGKDsb6I9sXihdt7w9s1bUgztEUy7QSUIkqTHzeHECsoymWiQ8o/XXwidsC4h1NsUyLElq1AeIdTbFMNQNii3c0xTI1AYh3NMUytQGIdTTFMi1LqlcH6HbFCSBCtQMiUzrzipuv2vdqHEs8JrxhQIzFiYwZW9OAaF+RfvhYw4BgW3hW5E1qhSp/3rzf1EuIddNYFde8tu7NK5V0Mf8fsN5WtwnoxmXuCVAu5DpZpgAiynxwQLMehr1HQLMkgAgJoFuUKYBalQAiJIAIJYBK7FltT8lktcSe1faUhDtK7FltTyhgtv5wk/Y0aEHrDjdpT30btPJwk/aER7HVh5u0J/GDCAkgQsOYdHY/y/6UZjXcwRM/1/mKF8qOfXx/R/eNv8Emwl8ZN54Gl8kazNIgL2ZGshUjvTmPOnsmtd9OFO4bf8PnW/fSyexfI240fi2+TNZgngaZ1c5RXOErumDacTq9eHEx3XDfxBvcAQ/dtydutK3d/N9SBS4WchSNTtOPPGAofLGJ610/tvjDfdk3dA2Bc6MBxCtwgUZsECsJPaGPP0zbzjZBBwjuy77hmFzP3GiOeOYVuEB9R7EreM06GNf5sybA1j3cl3uD+S+jb7xYY84qcIkK+0ElAV3ARlM3mmfFPAqggl3MdXlW1zG26vZdrMgSPIaJZBppf4gBy/h21+5gpIsswWMMshfOMJ884iR7o8NxId2B5ZqzBI8j2k27cBzFjxeoDXGjCV9ZJndzFNfqRDn63jyE+0bfcHLd3VzI32h3s/+kC1yseUvwdqiZS/D2p1sswWtKEjAjJIAIRUDQx6SLISWO4rffJwgbiIKQo3gxqWdJHCIhR9GEi33IWOSFIorXH78EUE/RBpkJ8PFVulhPyTDfzYCnH6C6W4kfREgAESocUWxPhSOK7al0RLE5FY8otiaJKBKKNkimqaOCDXVxV7XYaiTxgwgJIELpXMyss598YsZehSKK2lgjGcyQxpbgbVaZGjVcgieAkJKAmc2sxlUDt5NdXjDtdHWXKnLrEyNtnjxyl70aHaAMgYrgGG0xzAsgQpcv/7zYJyuc3Gr664+/7eJRu5DFtONv/1lIF3/58Ndhu/0RW7Ygu3z3xTz1zngYZlGYecVcspfNchPjdVwPZtX9Vvu0NgTkn0r69d3+YFJOdsIMgNywau993XAqvSEgt06u++bB6lyUioAcEri8mWXaEhDsvnJfvjNIX/996QPqfqoDkKnee1jvd1uhFqT9l7c8PgaAamlBNq1qBpZ79PVgg/xHOZNsF+CrURu0PSBbGedE3yH1DIbXjkxHT8A1HvUan+YaR7HtAfk6+FHl1p9p+tYR/KDu44IN+vLr6C71/KC9AXooCSBCAoiQACIkaR9CktUgJIAIJTFp079kgWJfcS72mvwjCvKAwsRRljD0BHOxkC6UI7qwEj/ISfwgLAFESLoYITHShGSYJySOIiGZahASQISkixESI01IhnlC4igSkqkGof8Breo0y2VpjSkAAAAASUVORK5CYII=" /><!-- --></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>optimal_perf_cv <span class="ot">&lt;-</span> <span class="fu">BT_perf</span>(BT_algo, <span class="at">method=</span><span class="st">&#39;cv&#39;</span>)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>optimal_perf_best_guest <span class="ot">&lt;-</span> <span class="fu">BT_perf</span>(BT_algo, <span class="at">plot.it =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## Using validation method...</code></pre>
</div>
<div id="summary" class="section level3">
<h3><code>summary</code></h3>
<p>This function allows to compute the relative influence and plot it.
It is in fact a wrapper for the <code>BT_relative_influence</code> which
is not intended to be used per end-user.</p>
<p>Up to now, the computation of the relative influence isn’t available
for the permutation approach. This one should still be developed.</p>
<p>Regarding the currently developed method, we used the results
furnished by <code>rpart.object</code>. In fact, each tree in the
expansion is built thanks to this package and is stored in the
<code>BT$BTIndivFits</code> list. Moreover, note that this algorithm has
been adapted from <code>rpart</code> itself and therefore cover special
cases (e.g. need to rescale for <code>anova</code> method).</p>
<p>One can then present the function’s arguments:</p>
<ul>
<li><code>object</code>: a <code>BTFit</code> object, i.e. the result of
the <code>BT</code> call.</li>
<li><code>n.iter</code>: the number of iterations to use to compute the
relative influence. This parameter is often set to the optimal number of
iterations. By default, all the built trees will be used.</li>
<li><code>method</code>: the function that has to be called to compute
the relative influence. As previously mentioned, only one approach is
currently available. This parameter should therefore remains set to its
default value.</li>
<li><code>normalize</code>: if the user wants to normalize the relative
influence such that the sum over all normalized relative influence sum
up to 100.</li>
<li><code>order_it</code>: indicates whether the user wants to sort the
relative influence or not.</li>
<li><code>cBars</code> and <code>plot_it</code>: relative influence plot
related parameters, respectively the number of bars to plot in the
barplot and a boolean specifying whether the plot is expected or
not.</li>
</ul>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(BT_algo)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<pre><code>##           var   rel_inf
## Age       Age 70.162422
## Sport  Gender 13.477682
## Gender  Sport  9.855048
## Split   Split  6.504847</code></pre>
</div>
<div id="predict-function" class="section level3">
<h3><code>predict</code> function</h3>
<p>Using the global fit on the training set (the unique fit if no
cross-validation), one can predict (S3 method) on a new database. Here
are the function arguments:</p>
<ul>
<li><code>object</code>: a <code>BTFit</code> object</li>
<li><code>newdata</code>: the new data set used to realize the
predictions.</li>
<li><code>n.iter</code>: the number of boosting iterations (i.e. the
number of trees) used to perform the predictions. Usually, all the
iterations (i.e. the trees) up to the best one are considered to build
the predictions. Please note that this parameter can be a vector. In
such a case, a matrix containing the predictions for each element in
<code>n.iter</code> will be returned.</li>
<li><code>type</code>: Specify if one wants to predict on the ‘response’
or the ‘link’ scale.</li>
<li><code>single.iter</code>: If set to <code>TRUE</code> only the
<code>n.iter</code> tree will be used to predict (i.e. not all the trees
up to <code>n.iter</code>).</li>
</ul>
<p>Please note that if the <code>keep.data</code> argument was set to
<code>TRUE</code> and if the <code>newdata</code> is not specified, the
prediction will be achieved on the original training set.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict (response scale) using all trees up to best validation iteration. </span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(BT_algo, <span class="at">n.iter =</span> optimal_perf_validation, <span class="at">type =</span> <span class="st">&#39;response&#39;</span>), <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## As newdata is missing or is not a data frame, the training set has been used thanks to the keep.data = TRUE parameter.</code></pre>
<pre><code>##  [1] 0.1512079 0.1374772 0.1479626 0.1501892 0.1551795 0.1532813 0.1334080
##  [8] 0.1412066 0.1363647 0.1244193</code></pre>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict (link scale) using all trees up the best iteration OOB/CV.</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(BT_algo, <span class="at">newdata =</span> dataset, <span class="at">n.iter =</span> <span class="fu">c</span>(optimal_perf_oob, optimal_perf_cv), <span class="at">type =</span> <span class="st">&#39;link&#39;</span>), <span class="dv">10</span>) </span></code></pre></div>
<pre><code>##            [,1]      [,2]
##  [1,] -1.886696 -1.881140
##  [2,] -1.987535 -2.013851
##  [3,] -1.911317 -1.910444
##  [4,] -1.895761 -1.901736
##  [5,] -1.859751 -1.853420
##  [6,] -1.858016 -1.864961
##  [7,] -2.027736 -2.075813
##  [8,] -1.962980 -1.977309
##  [9,] -2.000500 -2.043417
## [10,] -2.098513 -2.209579</code></pre>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict using only the 40th tree.</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(BT_algo, <span class="at">n.iter =</span> <span class="dv">40</span>, <span class="at">type =</span> <span class="st">&#39;response&#39;</span>, <span class="at">single.iter =</span> <span class="cn">TRUE</span>), <span class="dv">10</span>) </span></code></pre></div>
<pre><code>## As newdata is missing or is not a data frame, the training set has been used thanks to the keep.data = TRUE parameter.</code></pre>
<pre><code>##  [1] 1.0726613 0.7460608 1.0726613 0.9975383 1.0726613 1.0726613 0.7460608
##  [8] 1.0726613 0.7460608 0.9109593</code></pre>
</div>
<div id="print-function" class="section level3">
<h3><code>print</code> function</h3>
<p>One can also print the <code>BTFit</code> object (i.e. the result of
the <code>BT</code> call) using the <code>print</code> S3 method. The
later will display the call, the relative influence and the best
iteration depending on the methods (i.e. <code>validation</code>,
<code>OOB</code> and <code>cv</code>) available.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(BT_algo)</span></code></pre></div>
<pre><code>## BT(formula = as.formula(&quot;Y_normalized ~ Age + Sport + Split + Gender&quot;), 
##     data = dataset, ABT = F, n.iter = 300, train.fraction = 0.8, 
##     interaction.depth = 4, shrinkage = 0.01, bag.fraction = 0.5, 
##     colsample.bytree = 3, keep.data = T, is.verbose = F, cv.folds = 3, 
##     folds.id = NULL, n.cores = 1, weights = ExpoR, seed = 44)
## A boosting tree model with Tweedie parameter : 1  has been fitted.
##  300 iterations were performed.</code></pre>
<pre><code>## OOB generally underestimates the optimal number of iterations although predictive performance is reasonably competitive.
##             Using cv_folds&gt;1 when calling BT usually results in improved predictive performance.</code></pre>
<pre><code>## The best out-of-bag iteration was 136.
## The best cross-validation iteration was 243.
## The best validation-set iteration was 115.
## There were 4 predictors of which 4 had non-zero influence.</code></pre>
</div>
<div id="bt_more-function" class="section level3">
<h3><code>BT_more</code> function</h3>
<p>Sometimes, it might be useful to continue the training on further
iterations. This can happen e.g. if the initial <code>n.iter</code>
parameter was not set high enough and that the best iteration computed
corresponds to this value, meaning that the minimal error (and the
related iteration) has yet to be found. This training continuation can
be performed thanks to the <code>BT_more</code> function. This one has
the following argument:</p>
<ul>
<li><code>BTFit_object</code>: an initial <code>BT</code> call on which
we want to continue the training/perform more iterations.</li>
<li><code>new.n.iter</code>: number of new boosting/tree iterations to
compute. In total, the <code>BT</code> object will end up with
<code>n.iter + new.n.iter</code> iterations.</li>
<li><code>is.verbose</code>: whether or not the user wants to display
algorithm evolution.</li>
<li><code>seed</code>: optional parameter that allows reproducible
example.</li>
</ul>
<p>It will then return a <code>BTFit</code> object (as the
<code>BT</code> function does) augmented by the new boosting
iterations.</p>
<p>We emphasize that the call to this function call only be made if the
original <code>BT</code> call: * has no cross-validation; * has been
computed with <code>keep.data</code> parameter set to
<code>TRUE</code>.</p>
<p>We thus need to re-fit the first example (with <code>cv.folds</code>
set to 1 and <code>keep.data=TRUE</code>) to show the usage of this
function.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>BT_algo <span class="ot">&lt;-</span> <span class="fu">BT</span>(<span class="at">formula =</span> <span class="fu">as.formula</span>(<span class="st">&quot;Y_normalized ~ Age + Sport + Split + Gender&quot;</span>),</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">data =</span> dataset,</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">ABT =</span> F,</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">n.iter =</span> <span class="dv">300</span>,</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">train.fraction =</span> <span class="fl">0.8</span>,</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">interaction.depth =</span> <span class="dv">4</span>,</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">shrinkage =</span> <span class="fl">0.01</span>,</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">bag.fraction =</span> <span class="fl">0.5</span>,</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">colsample.bytree =</span> <span class="dv">3</span>,</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">keep.data =</span> T,</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">is.verbose =</span> F,</span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">cv.folds =</span> <span class="dv">1</span>,</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">folds.id =</span> <span class="cn">NULL</span>,</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>              <span class="at">n.cores =</span> <span class="dv">1</span>,</span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>              <span class="at">weights =</span> ExpoR,</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">seed =</span> <span class="dv">44</span>)</span></code></pre></div>
<p>We can then call the <code>BT_more</code> function to perform 100 new
iterations and use the new object as an usual <code>BTFit</code>
one.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>BT_algo_contd <span class="ot">&lt;-</span> <span class="fu">BT_more</span>(BT_algo, <span class="at">new.n.iter =</span> <span class="dv">100</span>, <span class="at">seed =</span> <span class="dv">404</span>)</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See parameter, predict, ...</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>BT_algo_contd<span class="sc">$</span>BTParams<span class="sc">$</span>n.iter</span></code></pre></div>
<pre><code>## [1] 400</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">predict</span>(BT_algo_contd, <span class="at">n.iter =</span> <span class="dv">350</span>, <span class="at">type=</span><span class="st">&#39;link&#39;</span>), <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## As newdata is missing or is not a data frame, the training set has been used thanks to the keep.data = TRUE parameter.</code></pre>
<pre><code>##  [1] -1.877675 -2.013065 -1.912127 -1.891241 -1.844825 -1.867253 -2.096570
##  [8] -1.993146 -2.056822 -2.284128</code></pre>
</div>
</div>
<div id="comparison-between-adaptive-boosting-tree-and-boosting-tree" class="section level2">
<h2>Comparison between Adaptive Boosting Tree and Boosting Tree</h2>
<p>In our first example, we decided to fit a Boosting Tree approach.
However, one can be interested in fitting an Adaptive Boosting Tree one.
We note that the cross-validation is relevant for the former case while
it might not be needed for the later one. In fact, by construction the
Adaptive Boosting Tree will naturally ends up to root node, which will
not bring more information. This is then a natural stopping
criterion.</p>
<p>This task can easily be achieved taking the same example as before
and setting <code>ABT</code> to <code>TRUE</code> instead of
<code>FALSE</code>. It is then left to the interested reader.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
